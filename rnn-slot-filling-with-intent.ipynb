{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Models for Joint Intent Detection and Slot Filling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOADING THE DATA\n",
    "One line of data looks like this:  \n",
    "  \n",
    "&nbsp; ORIGINAL SEQUENCE: &nbsp; BOS i want to fly from baltimore           to dallas           round        trip        EOS  \n",
    "&nbsp; LABELED SEQUENCE:  &nbsp;  O  O   O   O  O   O   B-fromloc.city_name O B-toloc.city_name B-round_trip I-round_trip  \n",
    "&nbsp; INTENT:  &nbsp; atis_flight\n",
    "  \n",
    "Segmented into a dictionary: [original sentence words, labeled sequence, intent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first line of data:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'BOS i want to fly from baltimore to dallas round trip EOS\\tO O O O O O B-fromloc.city_name O B-toloc.city_name B-round_trip I-round_trip atis_flight\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# convert an empty 2D list into an empty 1D list\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "index_seq2slot = lambda s, index2slot: [index2slot[i] for i in s]\n",
    "index_seq2word = lambda s, index2word: [index2word[i] for i in s]\n",
    "\n",
    "train_data = open(\"dataset/atis-2.train.w-intent.iob\", \"r\").readlines()\n",
    "test_data = open(\"dataset/atis-2.dev.w-intent.iob\", \"r\").readlines()\n",
    "\n",
    "print('This is the first line of data:')\n",
    "\n",
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['i', 'want', 'to', 'fly', 'from', 'baltimore', 'to', 'dallas', 'round', 'trip', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-round_trip', 'I-round_trip', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], 'atis_flight')\n"
     ]
    }
   ],
   "source": [
    "def data_pipeline(data, length=50):\n",
    "    '''\n",
    "    [length] represents the standard size of the sequence to be inputed in the model\n",
    "    This function will make sure that every line from the data has the same length\n",
    "    before it is fed in the model\n",
    "    '''\n",
    "    # remove the '\\n' spaces\n",
    "    data = [t[:-1] for t in data]\n",
    "    \n",
    "    # split the data by white spaces\n",
    "    data = [[t.split(\"\\t\")[0].split(\" \"), t.split(\"\\t\")[1].split(\" \")[:-1], t.split(\"\\t\")[1].split(\" \")[-1]] for t in\n",
    "            data]  \n",
    "    \n",
    "    # transform every line into a dictionary: [ORIGINAL data, LABELED data, and INTEND]\n",
    "    data = [[t[0][1:-1], t[1][1:], t[2]] for t in data]\n",
    "    seq_in, seq_out, intent = list(zip(*data))\n",
    "    \n",
    "    sin = []\n",
    "    sout = []\n",
    "    \n",
    "    # iterate through every line of the original seq\n",
    "    for line in range(len(seq_in)):\n",
    "        ### A D J U S T   T H E   S I Z E   O F   T H E   O R I G I N A L   S E Q U E N C E ###\n",
    "        temp = seq_in[line]\n",
    "        # if the line being read is shorter than 'length', this will apply padding to fill it\n",
    "        if len(temp) < length:\n",
    "            # <EOS> = End of Sentence\n",
    "            temp.append('<EOS>')\n",
    "            while len(temp) < length:\n",
    "                temp.append('<PAD>')\n",
    "        \n",
    "        # if the line being read is larger than 'length', this will cut it to adjust its size\n",
    "        else:\n",
    "            temp = temp[:length]\n",
    "            temp[-1] = '<EOS>'\n",
    "        sin.append(temp)\n",
    "        \n",
    "        ### A D J U S T   T H E   S I Z E   O F   T H E   L A B E L E D   S E Q U E N C E ###\n",
    "        temp = seq_out[line]\n",
    "        if len(temp) < length:\n",
    "            while len(temp) < length:\n",
    "                temp.append('<PAD>')\n",
    "        else:\n",
    "            temp = temp[:length]\n",
    "            temp[-1] = '<EOS>'\n",
    "        sout.append(temp)\n",
    "        data = list(zip(sin, sout, intent))\n",
    "        \n",
    "    return data\n",
    "\n",
    "# transform the data so every sequence has the same size/legth\n",
    "train_data_ed = data_pipeline(train_data)\n",
    "test_data_ed = data_pipeline(test_data)\n",
    "\n",
    "print(train_data_ed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAPPING DATA\n",
    "The following code will map the data from every list (original, labeled, and intents) creating dictionaries representing this information as index to words and viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " '<SOS>': 2,\n",
       " '<EOS>': 3,\n",
       " 'mealtime': 4,\n",
       " 'leaves': 5,\n",
       " 'sure': 6,\n",
       " 'operating': 7,\n",
       " '2': 8,\n",
       " 'cheap': 9,\n",
       " 'ap57': 10,\n",
       " 'listings': 11,\n",
       " '305': 12,\n",
       " '815': 13,\n",
       " 'travel': 14,\n",
       " 'way': 15,\n",
       " 'eleventh': 16,\n",
       " 'tacoma': 17,\n",
       " 'thursday': 18,\n",
       " 'eight': 19,\n",
       " 'reverse': 20,\n",
       " 'book': 21,\n",
       " 'i': 22,\n",
       " '106': 23,\n",
       " 'uses': 24,\n",
       " 'anywhere': 25,\n",
       " 'than': 26,\n",
       " 'do': 27,\n",
       " 'traveling': 28,\n",
       " 'lastest': 29,\n",
       " '6': 30,\n",
       " 'much': 31,\n",
       " 'intercontinental': 32,\n",
       " 'abbreviation': 33,\n",
       " 'fares': 34,\n",
       " 'georgia': 35,\n",
       " 'airfare': 36,\n",
       " 'hou': 37,\n",
       " 'depart': 38,\n",
       " 'itinerary': 39,\n",
       " 'reaches': 40,\n",
       " 'march': 41,\n",
       " '1991': 42,\n",
       " '505': 43,\n",
       " 'june': 44,\n",
       " '1505': 45,\n",
       " 'lake': 46,\n",
       " 'see': 47,\n",
       " '417': 48,\n",
       " 'begins': 49,\n",
       " 'connecting': 50,\n",
       " 'express': 51,\n",
       " '2134': 52,\n",
       " 'too': 53,\n",
       " 'by': 54,\n",
       " 'reservations': 55,\n",
       " '825': 56,\n",
       " '230': 57,\n",
       " 'chicago': 58,\n",
       " 'highest': 59,\n",
       " \"sunday's\": 60,\n",
       " 'sfo': 61,\n",
       " 'dinnertime': 62,\n",
       " 'around': 63,\n",
       " 'business': 64,\n",
       " 'milwaukee': 65,\n",
       " 'many': 66,\n",
       " 'put': 67,\n",
       " '723': 68,\n",
       " 'tuesdays': 69,\n",
       " \"atlanta's\": 70,\n",
       " '415': 71,\n",
       " '466': 72,\n",
       " '737': 73,\n",
       " 'reaching': 74,\n",
       " 'laying': 75,\n",
       " 'leave': 76,\n",
       " 'maximum': 77,\n",
       " '139': 78,\n",
       " 'thrift': 79,\n",
       " 'lowest': 80,\n",
       " '1288': 81,\n",
       " 'kind': 82,\n",
       " '852': 83,\n",
       " '210': 84,\n",
       " '200': 85,\n",
       " 'carried': 86,\n",
       " 'mitchell': 87,\n",
       " 'of': 88,\n",
       " 'while': 89,\n",
       " 'them': 90,\n",
       " 'cities': 91,\n",
       " 'one': 92,\n",
       " 'take': 93,\n",
       " 'transport': 94,\n",
       " 'whether': 95,\n",
       " 'arrive': 96,\n",
       " 'two': 97,\n",
       " 'plane': 98,\n",
       " 'houston': 99,\n",
       " 'sixteen': 100,\n",
       " 'less': 101,\n",
       " 'weekdays': 102,\n",
       " 'd10': 103,\n",
       " \"what're\": 104,\n",
       " 'ticket': 105,\n",
       " 'three': 106,\n",
       " '813': 107,\n",
       " 'field': 108,\n",
       " 'midnight': 109,\n",
       " 'symbols': 110,\n",
       " 'directly': 111,\n",
       " 'd9s': 112,\n",
       " 'belong': 113,\n",
       " 'catch': 114,\n",
       " 'schedule': 115,\n",
       " 'tickets': 116,\n",
       " 'nevada': 117,\n",
       " 'pm': 118,\n",
       " 'local': 119,\n",
       " 'this': 120,\n",
       " '445': 121,\n",
       " '217': 122,\n",
       " \"what's\": 123,\n",
       " 'iah': 124,\n",
       " 'should': 125,\n",
       " 'live': 126,\n",
       " 'landings': 127,\n",
       " 'for': 128,\n",
       " 'afternoon': 129,\n",
       " 'times': 130,\n",
       " 'columbus': 131,\n",
       " 'interested': 132,\n",
       " 'is': 133,\n",
       " 'level': 134,\n",
       " 'single': 135,\n",
       " '459': 136,\n",
       " '1245': 137,\n",
       " 'airport': 138,\n",
       " '201': 139,\n",
       " 'arrivals': 140,\n",
       " '1024': 141,\n",
       " \"i'm\": 142,\n",
       " 'least': 143,\n",
       " 'pennsylvania': 144,\n",
       " 'home': 145,\n",
       " 'fourth': 146,\n",
       " 'need': 147,\n",
       " 'jet': 148,\n",
       " 'fn': 149,\n",
       " 'repeat': 150,\n",
       " 'fare': 151,\n",
       " 'class': 152,\n",
       " 'equal': 153,\n",
       " 'qualify': 154,\n",
       " 'san': 155,\n",
       " '1055': 156,\n",
       " 'tomorrow': 157,\n",
       " 'august': 158,\n",
       " '1100': 159,\n",
       " 'distance': 160,\n",
       " 'la': 161,\n",
       " 'route': 162,\n",
       " 'repeating': 163,\n",
       " 'closest': 164,\n",
       " 'connects': 165,\n",
       " 'toronto': 166,\n",
       " 'having': 167,\n",
       " 'm80': 168,\n",
       " 'beginning': 169,\n",
       " 'these': 170,\n",
       " 'city': 171,\n",
       " 'new': 172,\n",
       " 'may': 173,\n",
       " '727': 174,\n",
       " 'northwest': 175,\n",
       " \"that's\": 176,\n",
       " '10': 177,\n",
       " 'charges': 178,\n",
       " 'airplanes': 179,\n",
       " 'daily': 180,\n",
       " 'c': 181,\n",
       " 'serving': 182,\n",
       " 'ff': 183,\n",
       " 'question': 184,\n",
       " 'carries': 185,\n",
       " 'seats': 186,\n",
       " 'planes': 187,\n",
       " 'people': 188,\n",
       " '3357': 189,\n",
       " 'want': 190,\n",
       " 'must': 191,\n",
       " 'classes': 192,\n",
       " 'nineteenth': 193,\n",
       " 'car': 194,\n",
       " 'saturday': 195,\n",
       " 'september': 196,\n",
       " 'bring': 197,\n",
       " 'dallas': 198,\n",
       " 'with': 199,\n",
       " 'usa': 200,\n",
       " 'including': 201,\n",
       " 'out': 202,\n",
       " '1115': 203,\n",
       " 'eleven': 204,\n",
       " 'look': 205,\n",
       " 'newark': 206,\n",
       " 'minimum': 207,\n",
       " 'includes': 208,\n",
       " 'other': 209,\n",
       " '1992': 210,\n",
       " 'united': 211,\n",
       " 'four': 212,\n",
       " 'name': 213,\n",
       " '720': 214,\n",
       " 'listed': 215,\n",
       " 'serviced': 216,\n",
       " 'please': 217,\n",
       " 'capacity': 218,\n",
       " 'date': 219,\n",
       " 'october': 220,\n",
       " 'baltimore': 221,\n",
       " 'month': 222,\n",
       " 'me': 223,\n",
       " 'oakland': 224,\n",
       " 'bna': 225,\n",
       " 'ontario': 226,\n",
       " 'some': 227,\n",
       " 'general': 228,\n",
       " 'be': 229,\n",
       " 'price': 230,\n",
       " 'everywhere': 231,\n",
       " 'takes': 232,\n",
       " 'seating': 233,\n",
       " 'turboprop': 234,\n",
       " 'great': 235,\n",
       " 'meaning': 236,\n",
       " 'both': 237,\n",
       " '57': 238,\n",
       " 'earliest': 239,\n",
       " 'airline': 240,\n",
       " 'economy': 241,\n",
       " 'else': 242,\n",
       " 'canadian': 243,\n",
       " '82': 244,\n",
       " 'first': 245,\n",
       " 'guardia': 246,\n",
       " 'just': 247,\n",
       " 'dl': 248,\n",
       " 'jose': 249,\n",
       " 'smallest': 250,\n",
       " 'delta': 251,\n",
       " 'stand': 252,\n",
       " 'when': 253,\n",
       " 'seattle': 254,\n",
       " 'continuing': 255,\n",
       " 'direct': 256,\n",
       " 'day': 257,\n",
       " '324': 258,\n",
       " 'preferably': 259,\n",
       " 'january': 260,\n",
       " 'kinds': 261,\n",
       " '771': 262,\n",
       " '1200': 263,\n",
       " 'tuesday': 264,\n",
       " 'scenario': 265,\n",
       " 'arrives': 266,\n",
       " 'able': 267,\n",
       " 'paul': 268,\n",
       " 'besides': 269,\n",
       " 'any': 270,\n",
       " 'eighth': 271,\n",
       " 'or': 272,\n",
       " '615': 273,\n",
       " '747': 274,\n",
       " \"i'd\": 275,\n",
       " 'flying': 276,\n",
       " 'very': 277,\n",
       " 'what': 278,\n",
       " '21': 279,\n",
       " 'm': 280,\n",
       " 'sorry': 281,\n",
       " 'approximately': 282,\n",
       " 'worth': 283,\n",
       " 'rates': 284,\n",
       " 'makes': 285,\n",
       " 'utah': 286,\n",
       " 'working': 287,\n",
       " 'gets': 288,\n",
       " 'connect': 289,\n",
       " 'friends': 290,\n",
       " '100': 291,\n",
       " 'ap': 292,\n",
       " 'late': 293,\n",
       " 'also': 294,\n",
       " 'nonstop': 295,\n",
       " '55': 296,\n",
       " 'have': 297,\n",
       " 'louis': 298,\n",
       " 'nighttime': 299,\n",
       " 'lufthansa': 300,\n",
       " 'twelfth': 301,\n",
       " 'non': 302,\n",
       " 'twentieth': 303,\n",
       " 'provides': 304,\n",
       " 'database': 305,\n",
       " 'it': 306,\n",
       " 'midwest': 307,\n",
       " 'mia': 308,\n",
       " 'airfares': 309,\n",
       " 'carolina': 310,\n",
       " '497766': 311,\n",
       " 'six': 312,\n",
       " '928': 313,\n",
       " 'starting': 314,\n",
       " '163': 315,\n",
       " 'second': 316,\n",
       " 'cp': 317,\n",
       " 'fourteenth': 318,\n",
       " 'about': 319,\n",
       " \"o'clock\": 320,\n",
       " 'my': 321,\n",
       " 'sundays': 322,\n",
       " 'departing': 323,\n",
       " 'downtown': 324,\n",
       " 'lunch': 325,\n",
       " 'goes': 326,\n",
       " 'alaska': 327,\n",
       " 'will': 328,\n",
       " '823': 329,\n",
       " '19': 330,\n",
       " 'restrictions': 331,\n",
       " '352': 332,\n",
       " 'expensive': 333,\n",
       " 'again': 334,\n",
       " 'wednesdays': 335,\n",
       " 'southwest': 336,\n",
       " 'pittsburgh': 337,\n",
       " 'oak': 338,\n",
       " '1220': 339,\n",
       " 'montreal': 340,\n",
       " 'most': 341,\n",
       " 'nashville': 342,\n",
       " '1700': 343,\n",
       " '402': 344,\n",
       " 'third': 345,\n",
       " 'jersey': 346,\n",
       " 'washington': 347,\n",
       " 'nonstops': 348,\n",
       " 'schedules': 349,\n",
       " 'sa': 350,\n",
       " 'north': 351,\n",
       " 'thursdays': 352,\n",
       " 'calling': 353,\n",
       " 'love': 354,\n",
       " 'reservation': 355,\n",
       " 'petersburg': 356,\n",
       " 'bur': 357,\n",
       " 'boston': 358,\n",
       " 'within': 359,\n",
       " 'ground': 360,\n",
       " 'york': 361,\n",
       " '329': 362,\n",
       " '1222': 363,\n",
       " '1600': 364,\n",
       " 'ten': 365,\n",
       " 'describe': 366,\n",
       " 'meals': 367,\n",
       " 'using': 368,\n",
       " 'possible': 369,\n",
       " \"one's\": 370,\n",
       " 'they': 371,\n",
       " 'florida': 372,\n",
       " 'restriction': 373,\n",
       " '1765': 374,\n",
       " 'land': 375,\n",
       " 'greatest': 376,\n",
       " 'yyz': 377,\n",
       " '212': 378,\n",
       " 'supper': 379,\n",
       " 'burbank': 380,\n",
       " 'limousines': 381,\n",
       " 'help': 382,\n",
       " 'detroit': 383,\n",
       " 'b': 384,\n",
       " '279': 385,\n",
       " '810': 386,\n",
       " 'booking': 387,\n",
       " 'jfk': 388,\n",
       " 'capacities': 389,\n",
       " 'along': 390,\n",
       " 'to': 391,\n",
       " 'mondays': 392,\n",
       " 'december': 393,\n",
       " '1145': 394,\n",
       " 'j31': 395,\n",
       " 'morning': 396,\n",
       " 'ac': 397,\n",
       " 'takeoffs': 398,\n",
       " 'another': 399,\n",
       " 'the': 400,\n",
       " 'travels': 401,\n",
       " 'hi': 402,\n",
       " 'night': 403,\n",
       " 'stopping': 404,\n",
       " 'nw': 405,\n",
       " 'county': 406,\n",
       " '555': 407,\n",
       " 'thirtieth': 408,\n",
       " 'grounds': 409,\n",
       " 'early': 410,\n",
       " '1850': 411,\n",
       " 'stopovers': 412,\n",
       " '345': 413,\n",
       " \"friday's\": 414,\n",
       " 'heading': 415,\n",
       " 'has': 416,\n",
       " 'trips': 417,\n",
       " '934': 418,\n",
       " '400': 419,\n",
       " 'q': 420,\n",
       " 'start': 421,\n",
       " 'us': 422,\n",
       " 'latest': 423,\n",
       " 'limo': 424,\n",
       " 'oh': 425,\n",
       " 'include': 426,\n",
       " 'red': 427,\n",
       " \"we're\": 428,\n",
       " 'located': 429,\n",
       " 'yn': 430,\n",
       " 'train': 431,\n",
       " 'various': 432,\n",
       " '4': 433,\n",
       " 'costs': 434,\n",
       " '1500': 435,\n",
       " 'minnesota': 436,\n",
       " 'only': 437,\n",
       " 'used': 438,\n",
       " 'layover': 439,\n",
       " '343': 440,\n",
       " 'more': 441,\n",
       " 'wednesday': 442,\n",
       " 'today': 443,\n",
       " 'dulles': 444,\n",
       " 'trip': 445,\n",
       " '730': 446,\n",
       " 'transcontinental': 447,\n",
       " 'ls': 448,\n",
       " '1940': 449,\n",
       " 'give': 450,\n",
       " '43': 451,\n",
       " 'either': 452,\n",
       " 'last': 453,\n",
       " '137338': 454,\n",
       " 'monday': 455,\n",
       " 'okay': 456,\n",
       " 'difference': 457,\n",
       " 'visit': 458,\n",
       " '150': 459,\n",
       " 'concerning': 460,\n",
       " 'america': 461,\n",
       " \"don't\": 462,\n",
       " 'lands': 463,\n",
       " 'fit': 464,\n",
       " 'landing': 465,\n",
       " 'dinner': 466,\n",
       " 'at': 467,\n",
       " 'area': 468,\n",
       " 'shortest': 469,\n",
       " 'largest': 470,\n",
       " 'flight': 471,\n",
       " 'earlier': 472,\n",
       " '1130': 473,\n",
       " 'there': 474,\n",
       " 'make': 475,\n",
       " 'charlotte': 476,\n",
       " 'over': 477,\n",
       " 'represented': 478,\n",
       " 'flights': 479,\n",
       " 'later': 480,\n",
       " 'sunday': 481,\n",
       " 'a': 482,\n",
       " '1205': 483,\n",
       " 'texas': 484,\n",
       " 'philadelphia': 485,\n",
       " '8': 486,\n",
       " '3': 487,\n",
       " 'display': 488,\n",
       " \"i've\": 489,\n",
       " 'continental': 490,\n",
       " 'number': 491,\n",
       " 'use': 492,\n",
       " 'phoenix': 493,\n",
       " 'ohio': 494,\n",
       " 'into': 495,\n",
       " 'staying': 496,\n",
       " 'mean': 497,\n",
       " 'canada': 498,\n",
       " '2153': 499,\n",
       " 'seventeenth': 500,\n",
       " 'tell': 501,\n",
       " 'zone': 502,\n",
       " 'provided': 503,\n",
       " 'that': 504,\n",
       " 'but': 505,\n",
       " 'tennessee': 506,\n",
       " 'requesting': 507,\n",
       " 'next': 508,\n",
       " 'trans': 509,\n",
       " 'dollars': 510,\n",
       " '3724': 511,\n",
       " 'american': 512,\n",
       " 'y': 513,\n",
       " 'thing': 514,\n",
       " 'cheapest': 515,\n",
       " 'quebec': 516,\n",
       " 'order': 517,\n",
       " 'toward': 518,\n",
       " 'qo': 519,\n",
       " 'somebody': 520,\n",
       " 'serve': 521,\n",
       " 'does': 522,\n",
       " 'kansas': 523,\n",
       " 'april': 524,\n",
       " 'total': 525,\n",
       " '7': 526,\n",
       " 'seven': 527,\n",
       " 'coach': 528,\n",
       " '80': 529,\n",
       " 'november': 530,\n",
       " 'prefer': 531,\n",
       " 'logan': 532,\n",
       " 'saturdays': 533,\n",
       " '845': 534,\n",
       " 'numbers': 535,\n",
       " 'eastern': 536,\n",
       " '1': 537,\n",
       " 'enroute': 538,\n",
       " 'operation': 539,\n",
       " 'once': 540,\n",
       " '733': 541,\n",
       " 'town': 542,\n",
       " '650': 543,\n",
       " '1026': 544,\n",
       " '1230': 545,\n",
       " '296': 546,\n",
       " \"delta's\": 547,\n",
       " 'michigan': 548,\n",
       " 'airlines': 549,\n",
       " 'final': 550,\n",
       " 'atlanta': 551,\n",
       " 'am': 552,\n",
       " '1039': 553,\n",
       " 'twa': 554,\n",
       " 'international': 555,\n",
       " 'week': 556,\n",
       " '746': 557,\n",
       " '71': 558,\n",
       " '1045': 559,\n",
       " 'f': 560,\n",
       " 'seventh': 561,\n",
       " 'options': 562,\n",
       " 'listing': 563,\n",
       " 'february': 564,\n",
       " 'fly': 565,\n",
       " 'serves': 566,\n",
       " 'originating': 567,\n",
       " 'yes': 568,\n",
       " 'runs': 569,\n",
       " 'following': 570,\n",
       " 'destination': 571,\n",
       " 'missouri': 572,\n",
       " 'time': 573,\n",
       " 'world': 574,\n",
       " '12': 575,\n",
       " '110': 576,\n",
       " 'thereafter': 577,\n",
       " 'economic': 578,\n",
       " 'ninth': 579,\n",
       " '734': 580,\n",
       " 'arrival': 581,\n",
       " 'how': 582,\n",
       " 'wants': 583,\n",
       " 'which': 584,\n",
       " 'here': 585,\n",
       " 'rental': 586,\n",
       " '705': 587,\n",
       " 'stopover': 588,\n",
       " 'if': 589,\n",
       " 'up': 590,\n",
       " 'their': 591,\n",
       " 'seventeen': 592,\n",
       " 'eye': 593,\n",
       " 'meal': 594,\n",
       " '311': 595,\n",
       " 'explain': 596,\n",
       " '1030': 597,\n",
       " 'after': 598,\n",
       " 'straight': 599,\n",
       " 'colorado': 600,\n",
       " 'are': 601,\n",
       " 'transportation': 602,\n",
       " 'actually': 603,\n",
       " 'during': 604,\n",
       " 'takeoff': 605,\n",
       " 'departs': 606,\n",
       " 'say': 607,\n",
       " '932': 608,\n",
       " 'your': 609,\n",
       " 'thank': 610,\n",
       " 'information': 611,\n",
       " '416': 612,\n",
       " 'los': 613,\n",
       " 'equipment': 614,\n",
       " 'choices': 615,\n",
       " 'available': 616,\n",
       " 'evening': 617,\n",
       " '1291': 618,\n",
       " 'coming': 619,\n",
       " '257': 620,\n",
       " '72s': 621,\n",
       " 'tower': 622,\n",
       " 'in': 623,\n",
       " 'far': 624,\n",
       " '1020': 625,\n",
       " 'arriving': 626,\n",
       " '315': 627,\n",
       " 'then': 628,\n",
       " 'priced': 629,\n",
       " 'offered': 630,\n",
       " 'close': 631,\n",
       " 'dc': 632,\n",
       " 'show': 633,\n",
       " 'mco': 634,\n",
       " '269': 635,\n",
       " 'still': 636,\n",
       " '757': 637,\n",
       " 'right': 638,\n",
       " 'twenty': 639,\n",
       " 'originate': 640,\n",
       " 'wish': 641,\n",
       " 'eighteenth': 642,\n",
       " 'st.': 643,\n",
       " 'advertises': 644,\n",
       " 'through': 645,\n",
       " 'thirty': 646,\n",
       " 'fifteenth': 647,\n",
       " '2100': 648,\n",
       " 'got': 649,\n",
       " 'memphis': 650,\n",
       " 'noon': 651,\n",
       " 'via': 652,\n",
       " 'near': 653,\n",
       " 'connections': 654,\n",
       " 'companies': 655,\n",
       " 'ord': 656,\n",
       " '630': 657,\n",
       " '0900': 658,\n",
       " 'code': 659,\n",
       " 'taking': 660,\n",
       " 'afternoons': 661,\n",
       " 'now': 662,\n",
       " 'vegas': 663,\n",
       " 'and': 664,\n",
       " 'flies': 665,\n",
       " 'round': 666,\n",
       " '5': 667,\n",
       " 'hello': 668,\n",
       " 'like': 669,\n",
       " 'cars': 670,\n",
       " 'types': 671,\n",
       " 'returning': 672,\n",
       " 'under': 673,\n",
       " 'airplane': 674,\n",
       " 'pearson': 675,\n",
       " '1209': 676,\n",
       " 'aa': 677,\n",
       " '767': 678,\n",
       " 'snack': 679,\n",
       " 'go': 680,\n",
       " 'buy': 681,\n",
       " \"doesn't\": 682,\n",
       " 'list': 683,\n",
       " 'lester': 684,\n",
       " 'amount': 685,\n",
       " 'year': 686,\n",
       " '500': 687,\n",
       " 'different': 688,\n",
       " 'hp': 689,\n",
       " 'scheduled': 690,\n",
       " '515': 691,\n",
       " '1133': 692,\n",
       " 'diego': 693,\n",
       " 'co': 694,\n",
       " 'looking': 695,\n",
       " 'abbreviations': 696,\n",
       " 'sort': 697,\n",
       " 'define': 698,\n",
       " 'qw': 699,\n",
       " 'an': 700,\n",
       " 'place': 701,\n",
       " '645': 702,\n",
       " 'stands': 703,\n",
       " 'find': 704,\n",
       " 'run': 705,\n",
       " 'all': 706,\n",
       " '405': 707,\n",
       " 'fifth': 708,\n",
       " 'lives': 709,\n",
       " \"i'll\": 710,\n",
       " 'cleveland': 711,\n",
       " 'noontime': 712,\n",
       " '323': 713,\n",
       " 'days': 714,\n",
       " 'angeles': 715,\n",
       " 'served': 716,\n",
       " 'h': 717,\n",
       " 'leaving': 718,\n",
       " '73s': 719,\n",
       " 'offers': 720,\n",
       " 'denver': 721,\n",
       " 'across': 722,\n",
       " '300': 723,\n",
       " 'fine': 724,\n",
       " 'get': 725,\n",
       " 'nationair': 726,\n",
       " 'beach': 727,\n",
       " 'atl': 728,\n",
       " 'return': 729,\n",
       " 'sixteenth': 730,\n",
       " 'vicinity': 731,\n",
       " 'rent': 732,\n",
       " 'long': 733,\n",
       " 'taxi': 734,\n",
       " 'as': 735,\n",
       " 'airports': 736,\n",
       " 'mornings': 737,\n",
       " 'back': 738,\n",
       " 'arizona': 739,\n",
       " 'you': 740,\n",
       " 'indiana': 741,\n",
       " 'july': 742,\n",
       " 'rentals': 743,\n",
       " \"york's\": 744,\n",
       " 'on': 745,\n",
       " '755': 746,\n",
       " 'ap80': 747,\n",
       " 'francisco': 748,\n",
       " '4400': 749,\n",
       " 'locate': 750,\n",
       " 'indianapolis': 751,\n",
       " 'could': 752,\n",
       " 'arrange': 753,\n",
       " 'so': 754,\n",
       " 'inform': 755,\n",
       " 'departure': 756,\n",
       " 'inexpensive': 757,\n",
       " 'dfw': 758,\n",
       " '1300': 759,\n",
       " 'offer': 760,\n",
       " 'type': 761,\n",
       " 'ua': 762,\n",
       " 'weekday': 763,\n",
       " 'philly': 764,\n",
       " '1993': 765,\n",
       " 'salt': 766,\n",
       " 'boeing': 767,\n",
       " 'no': 768,\n",
       " 'regarding': 769,\n",
       " 'west': 770,\n",
       " 'midway': 771,\n",
       " 'come': 772,\n",
       " 'qx': 773,\n",
       " '420': 774,\n",
       " '270': 775,\n",
       " 'provide': 776,\n",
       " 'soon': 777,\n",
       " 'rate': 778,\n",
       " '130': 779,\n",
       " '1000': 780,\n",
       " 'breakfast': 781,\n",
       " 'from': 782,\n",
       " 'sd': 783,\n",
       " 'ea': 784,\n",
       " 'hartfield': 785,\n",
       " 'service': 786,\n",
       " 'las': 787,\n",
       " 'cincinnati': 788,\n",
       " 'well': 789,\n",
       " 'prices': 790,\n",
       " 'ewr': 791,\n",
       " 'california': 792,\n",
       " 'making': 793,\n",
       " 'know': 794,\n",
       " '838': 795,\n",
       " \"american's\": 796,\n",
       " 'between': 797,\n",
       " 'those': 798,\n",
       " 'before': 799,\n",
       " 'proper': 800,\n",
       " \"it's\": 801,\n",
       " '229': 802,\n",
       " '297': 803,\n",
       " 'hours': 804,\n",
       " 'going': 805,\n",
       " 'air': 806,\n",
       " 'codes': 807,\n",
       " '225': 808,\n",
       " \"wednesday's\": 809,\n",
       " 's': 810,\n",
       " 'stapleton': 811,\n",
       " 'who': 812,\n",
       " 'stop': 813,\n",
       " '11': 814,\n",
       " 'd': 815,\n",
       " '718': 816,\n",
       " '819': 817,\n",
       " \"let's\": 818,\n",
       " 'orlando': 819,\n",
       " 'limousine': 820,\n",
       " 'designate': 821,\n",
       " 'without': 822,\n",
       " 'plan': 823,\n",
       " 'sixth': 824,\n",
       " 'sometime': 825,\n",
       " 'continent': 826,\n",
       " '1017': 827,\n",
       " 'departures': 828,\n",
       " 'being': 829,\n",
       " 'trying': 830,\n",
       " 'same': 831,\n",
       " 'let': 832,\n",
       " 'aircraft': 833,\n",
       " 'tenth': 834,\n",
       " 'westchester': 835,\n",
       " 'bwi': 836,\n",
       " '539': 837,\n",
       " 'spend': 838,\n",
       " 'miami': 839,\n",
       " 'connection': 840,\n",
       " 'minneapolis': 841,\n",
       " 'fort': 842,\n",
       " 'thirteenth': 843,\n",
       " 'arrangements': 844,\n",
       " 'can': 845,\n",
       " 'would': 846,\n",
       " 'bound': 847,\n",
       " 'wanted': 848,\n",
       " 'stops': 849,\n",
       " '530': 850,\n",
       " 'where': 851,\n",
       " '281': 852,\n",
       " 'cost': 853,\n",
       " 'dc10': 854,\n",
       " 'currently': 855,\n",
       " '1158': 856,\n",
       " '98': 857,\n",
       " 'f28': 858,\n",
       " 'friday': 859,\n",
       " 'each': 860,\n",
       " '430': 861,\n",
       " '1110': 862,\n",
       " 'passengers': 863,\n",
       " 'such': 864,\n",
       " 'names': 865,\n",
       " 'services': 866,\n",
       " '9': 867,\n",
       " 'hopefully': 868,\n",
       " 'tampa': 869,\n",
       " 'instead': 870}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_info_from_training_data(data):\n",
    "    seq_in, seq_out, intent = list(zip(*data))\n",
    "    vocab = set(flatten(seq_in))\n",
    "    slot_tag = set(flatten(seq_out))\n",
    "    intent_tag = set(intent)\n",
    "    \n",
    "    # generate word2index\n",
    "    word2index = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
    "    for token in vocab:\n",
    "        if token not in word2index.keys():\n",
    "            word2index[token] = len(word2index)\n",
    "\n",
    "    # generate index2word\n",
    "    index2word = {v: k for k, v in word2index.items()}\n",
    "\n",
    "    # generate tag2index\n",
    "    tag2index = {'<PAD>': 0, '<UNK>': 1, \"O\": 2}\n",
    "    for tag in slot_tag:\n",
    "        if tag not in tag2index.keys():\n",
    "            tag2index[tag] = len(tag2index)\n",
    "\n",
    "    # generate index2tag\n",
    "    index2tag = {v: k for k, v in tag2index.items()}\n",
    "\n",
    "    # generate intent2index\n",
    "    intent2index = {'<UNK>': 0}\n",
    "    for ii in intent_tag:\n",
    "        if ii not in intent2index.keys():\n",
    "            intent2index[ii] = len(intent2index)\n",
    "\n",
    "    # generate index2intent\n",
    "    index2intent = {v: k for k, v in intent2index.items()}\n",
    "    return word2index, index2word, tag2index, index2tag, intent2index, index2intent\n",
    "\n",
    "\n",
    "word2index, index2word, slot2index, index2slot, intent2index, index2intent = \\\n",
    "        get_info_from_training_data(train_data_ed)\n",
    "    \n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRANSLATE ITEMS TO NUMBER\n",
    "This section of the code will replace each word on every sequence with an ID number (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING AND TESTING DATA STRUCTURE:\n",
      "ORIGINAL_index | UNPADDED_seqLength | LABELED_index | INDENT\n",
      "\n",
      "[[22, 190, 391, 565, 782, 221, 391, 198, 666, 445, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 10, [2, 2, 2, 2, 2, 49, 2, 28, 103, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 20]\n"
     ]
    }
   ],
   "source": [
    "def to_index(train, word2index, slot2index, intent2index):\n",
    "    new_train = []\n",
    "    for sin, sout, intent in train:\n",
    "        sin_ix = list(map(lambda i: word2index[i] if i in word2index else word2index[\"<UNK>\"],\n",
    "                          sin))\n",
    "        true_length = sin.index(\"<EOS>\")\n",
    "        sout_ix = list(map(lambda i: slot2index[i] if i in slot2index else slot2index[\"<UNK>\"],\n",
    "                           sout))\n",
    "        intent_ix = intent2index[intent] if intent in intent2index else intent2index[\"<UNK>\"]\n",
    "        new_train.append([sin_ix, true_length, sout_ix, intent_ix])\n",
    "    return new_train\n",
    "\n",
    "index_train = to_index(train_data_ed, word2index, slot2index, intent2index)\n",
    "index_test = to_index(test_data_ed, word2index, slot2index, intent2index)\n",
    "\n",
    "print('TRAINING AND TESTING DATA STRUCTURE:')\n",
    "print('ORIGINAL_index | UNPADDED_seqLength | LABELED_index | INDENT\\n')\n",
    "print(index_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURE\n",
    "\n",
    "### Tensorflow with dynamic rnn\n",
    "\n",
    "`tf.nn.rnn creates an unrolled graph for a fixed RNN length. That means, if you call tf.nn.rnn with inputs having 200 time steps you are creating a static graph with 200 RNN steps. First, graph creation is slow. Second, you’re unable to pass in longer sequences (> 200) than you’ve originally specified.tf.nn.dynamic_rnn solves this. It uses a tf.While loop to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size.`\n",
    "\n",
    "[Whats the difference between tensorflow dynamic_rnn and rnn?](https://stackoverflow.com/questions/39734146/whats-the-difference-between-tensorflow-dynamic-rnn-and-rnn) . That is, the static rnn must be expanded ahead of time. At the time of execution, the graph is fixed and the maximum length is limited. While the dynamic rnn can be cyclically multiplexed during execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_lookup:0' shape=(50, 16, 64) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "input_steps = 50      # specified length size\n",
    "embedding_size = 64\n",
    "hidden_size = 100\n",
    "n_layers = 2\n",
    "batch_size = 16\n",
    "vocab_size = 871\n",
    "slot_size = 122\n",
    "intent_size = 22\n",
    "epoch_num = 15\n",
    "\n",
    "######  E N C O D E R   A N D   D E C O D E R  ######\n",
    "encoder_inputs = tf.placeholder(tf.int32,[input_steps,batch_size],name='encoder_inputs')\n",
    "\n",
    "# The actual length of each sentence without padding\n",
    "encoder_inputs_actual_length = tf.placeholder(tf.int32, [batch_size],\n",
    "                                                   name='encoder_inputs_actual_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(tf.int32, [batch_size, input_steps],\n",
    "                                      name='decoder_targets')\n",
    "\n",
    "intent_targets = tf.placeholder(tf.int32, [batch_size],\n",
    "                                     name='intent_targets')\n",
    "\n",
    "######  E M B E D D I N G  ######\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size],\n",
    "                                           -0.1, 0.1), dtype=tf.float32, name=\"embedding\")\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "encoder_inputs_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs:  Tensor(\"concat:0\", shape=(50, 16, 200), dtype=float32)\n",
      "encoder_outputs[0]:  Tensor(\"strided_slice:0\", shape=(16, 200), dtype=float32)\n",
      "encoder_final_state_c:  Tensor(\"concat_1:0\", shape=(16, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n",
    "\n",
    "# Use a single LSTM cell\n",
    "encoder_f_cell = LSTMCell(hidden_size)\n",
    "encoder_b_cell = LSTMCell(hidden_size)\n",
    "\n",
    "# The size of the following four variables: T*B*D, T*B*D, B*D, B*D\n",
    "(encoder_fw_outputs, encoder_bw_outputs), (encoder_fw_final_state, encoder_bw_final_state) = \\\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_f_cell,\n",
    "                                    cell_bw=encoder_b_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_actual_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h)\n",
    "\n",
    "print(\"encoder_outputs: \", encoder_outputs)\n",
    "print(\"encoder_outputs[0]: \", encoder_outputs[0])\n",
    "print(\"encoder_final_state_c: \", encoder_final_state_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DECODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lengths = encoder_inputs_actual_length\n",
    "\n",
    "slot_W = tf.Variable(tf.random_uniform([hidden_size * 2, slot_size], -1, 1),\n",
    "                             dtype=tf.float32, name=\"slot_W\")\n",
    "slot_b = tf.Variable(tf.zeros([slot_size]), dtype=tf.float32, name=\"slot_b\")\n",
    "intent_W = tf.Variable(tf.random_uniform([hidden_size * 2, intent_size], -0.1, 0.1),\n",
    "                               dtype=tf.float32, name=\"intent_W\")\n",
    "intent_b = tf.Variable(tf.zeros([intent_size]), dtype=tf.float32, name=\"intent_b\")\n",
    "\n",
    "# start intent\n",
    "intent_logits = tf.add(tf.matmul(encoder_final_state_h, intent_W), intent_b)\n",
    "intent = tf.argmax(intent_logits, axis=1)\n",
    "\n",
    "sos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='SOS') * 2\n",
    "sos_step_embedded = tf.nn.embedding_lookup(embeddings, sos_time_slice)\n",
    "pad_step_embedded = tf.zeros([batch_size, hidden_size * 2 + embedding_size],\n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the Encoder above, the standard `tf.nn.dynamic_rnn` requires all input to be prepended to a tensor in advance.\n",
    "\n",
    "When the Decoder needs to use the output of the previous time node, it is not possible to package it in advance. The standard dynamic rnn is equivalent to: $s_i = f(s_{i-1}, x_i)$; but if the parameters of this function need to be extended, for example we do: $s_i = f(s_{i-1}, Y_{i-1}, h_i, c_i)$.\n",
    "\n",
    "So we need Hack: Use `tf.contrib.seq2seq.CustomHelper` to pass in three functions:\n",
    "\n",
    "- `initial_fn()`：The first point of time input.\n",
    "- `sample_fn()`：How to determine a certain fixed category id from logit to.\n",
    "- `next_inputs_fn()`：Determine the input of the general time point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  BasicDecoderOutput(rnn_output=<tf.Tensor 'decode/decoder/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, 16, 122) dtype=float32>, sample_id=<tf.Tensor 'decode/decoder/TensorArrayStack_1/TensorArrayGatherV3:0' shape=(?, 16) dtype=int32>)\n",
      "outputs.rnn_output:  Tensor(\"decode/decoder/TensorArrayStack/TensorArrayGatherV3:0\", shape=(?, 16, 122), dtype=float32)\n",
      "outputs.sample_id:  Tensor(\"decode/decoder/TensorArrayStack_1/TensorArrayGatherV3:0\", shape=(?, 16), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def initial_fn():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    initial_input = tf.concat((sos_step_embedded, encoder_outputs[0]), 1)\n",
    "    return initial_elements_finished, initial_input\n",
    "\n",
    "def sample_fn(time, outputs, state):\n",
    "    # Select logit's largest subscript as sample\n",
    "    prediction_id = tf.to_int32(tf.argmax(outputs, axis=1))\n",
    "    return prediction_id\n",
    "\n",
    "def next_inputs_fn(time, outputs, state, sample_ids):\n",
    "    # The output class on the previous time node, gets embedding and enters as the next time node\n",
    "    pred_embedding = tf.nn.embedding_lookup(embeddings, sample_ids)\n",
    "    # The input is h_i+o_{i-1}+c_i\n",
    "    next_input = tf.concat((pred_embedding, encoder_outputs[time]), 1)\n",
    "    elements_finished = (time >= decoder_lengths)  # this operation produces boolean tensor of [batch_size]\n",
    "    all_finished = tf.reduce_all(elements_finished)  # -> boolean scalar\n",
    "    next_inputs = tf.cond(all_finished, lambda: pad_step_embedded, lambda: next_input)\n",
    "    next_state = state\n",
    "    return elements_finished, next_inputs, next_state\n",
    "\n",
    "# Define your own helper\n",
    "my_helper = tf.contrib.seq2seq.CustomHelper(initial_fn, sample_fn, next_inputs_fn)\n",
    "\n",
    "def decode(helper, scope, reuse=None):\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        memory = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "            num_units=hidden_size, memory=memory,\n",
    "            memory_sequence_length=encoder_inputs_actual_length)\n",
    "        cell = tf.contrib.rnn.LSTMCell(num_units=hidden_size * 2)\n",
    "        attn_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "            cell, attention_mechanism, attention_layer_size=hidden_size)\n",
    "        out_cell = tf.contrib.rnn.OutputProjectionWrapper(\n",
    "            attn_cell, slot_size, reuse=reuse\n",
    "        )\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            cell=out_cell, helper=helper,\n",
    "            initial_state=out_cell.zero_state(\n",
    "                dtype=tf.float32, batch_size=batch_size))\n",
    "        # initial_state=encoder_final_state)\n",
    "        final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder=decoder, output_time_major=True,\n",
    "            impute_finished=True, maximum_iterations=input_steps\n",
    "        )\n",
    "        return final_outputs\n",
    "    \n",
    "outputs = decode(my_helper, 'decode')\n",
    "\n",
    "print(\"outputs: \", outputs)\n",
    "print(\"outputs.rnn_output: \", outputs.rnn_output)\n",
    "print(\"outputs.sample_id: \", outputs.sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_targets_true_length:  Tensor(\"strided_slice_1:0\", shape=(?, 16), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "decoder_prediction = outputs.sample_id\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(outputs.rnn_output))\n",
    "decoder_targets_time_majored = tf.transpose(decoder_targets, [1, 0])\n",
    "decoder_targets_true_length = decoder_targets_time_majored[:decoder_max_steps]\n",
    "print(\"decoder_targets_true_length: \", decoder_targets_true_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-f59a4c3299e1>:11: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define mask so that padding does not count towards loss\n",
    "mask = tf.to_float(tf.not_equal(decoder_targets_true_length, 0))\n",
    "\n",
    "# Defining the loss of the slot label\n",
    "loss_slot = tf.contrib.seq2seq.sequence_loss(\n",
    "    outputs.rnn_output, decoder_targets_true_length, weights=mask)\n",
    "\n",
    "# Defining loss of intent classification\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(intent_targets, depth=intent_size, dtype=tf.float32),\n",
    "    logits=intent_logits)\n",
    "loss_intent = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRICS FUNCTIONS\n",
    "import numpy.ma as ma\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "loss = loss_slot + loss_intent\n",
    "optimizer = tf.train.AdamOptimizer(name=\"a_optimizer\")\n",
    "grads, vars = zip(*optimizer.compute_gradients(loss))\n",
    "gradients, _ = tf.clip_by_global_norm(grads, 5)  # clip gradients\n",
    "train_op = optimizer.apply_gradients(zip(grads, vars))\n",
    "\n",
    "def step(sess, mode, trarin_batch):\n",
    "    \"\"\" perform each batch\"\"\"\n",
    "    if mode not in ['train', 'test']:\n",
    "        print >> sys.stderr, 'mode is not supported'\n",
    "        sys.exit(1)\n",
    "    unziped = list(zip(*trarin_batch))\n",
    "    if mode == 'train':\n",
    "        output_feeds = [train_op, loss, decoder_prediction,\n",
    "                        intent]\n",
    "        feed_dict = {encoder_inputs: np.transpose(unziped[0], [1, 0]),\n",
    "                     encoder_inputs_actual_length: unziped[1],\n",
    "                     decoder_targets: unziped[2],\n",
    "                     intent_targets: unziped[3]}\n",
    "    if mode in ['test']:\n",
    "        output_feeds = [decoder_prediction, intent]\n",
    "        feed_dict = {encoder_inputs: np.transpose(unziped[0], [1, 0]),\n",
    "                     encoder_inputs_actual_length: unziped[1]}\n",
    "\n",
    "    results = sess.run(output_feeds, feed_dict=feed_dict)\n",
    "    return results\n",
    "\n",
    "def accuracy_score(true_data, pred_data, true_length=None):\n",
    "    true_data = np.array(true_data)\n",
    "    pred_data = np.array(pred_data)\n",
    "    assert true_data.shape == pred_data.shape\n",
    "    if true_length is not None:\n",
    "        val_num = np.sum(true_length)\n",
    "        assert val_num != 0\n",
    "        res = 0\n",
    "        for i in range(true_data.shape[0]):\n",
    "            res += np.sum(true_data[i, :true_length[i]] == pred_data[i, :true_length[i]])\n",
    "    else:\n",
    "        val_num = np.prod(true_data.shape)\n",
    "        assert val_num != 0\n",
    "        res = np.sum(true_data == pred_data)\n",
    "    res /= float(val_num)\n",
    "    return res\n",
    "\n",
    "def get_data_from_sequence_batch(true_batch, pred_batch, padding_token):\n",
    "    \"\"\"Extract data from a sequence of batches：\n",
    "    [[3,1,2,0,0,0],[5,2,1,4,0,0]] -> [3,1,2,5,2,1,4]\"\"\"\n",
    "    true_ma = ma.masked_equal(true_batch, padding_token)\n",
    "    pred_ma = ma.masked_array(pred_batch, true_ma.mask)\n",
    "    true_ma = true_ma.flatten()\n",
    "    pred_ma = pred_ma.flatten()\n",
    "    true_ma = true_ma[~true_ma.mask]\n",
    "    pred_ma = pred_ma[~pred_ma.mask]\n",
    "    return true_ma, pred_ma\n",
    "\n",
    "def f1_for_sequence_batch(true_batch, pred_batch, average=\"micro\", padding_token=0):\n",
    "    true, pred = get_data_from_sequence_batch(true_batch, pred_batch, padding_token)\n",
    "    labels = list(set(true))\n",
    "    return f1_score(true, pred, labels=labels, average=average)\n",
    "\n",
    "def accuracy_for_sequence_batch(true_batch, pred_batch, padding_token=0):\n",
    "    true, pred = get_data_from_sequence_batch(true_batch, pred_batch, padding_token)\n",
    "    return accuracy_score(true, pred)\n",
    "\n",
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "        \n",
    "def getBatch2(batch_size, train_data):\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss at epoch 0, step 0: 7.889609\n",
      "Average train loss at epoch 0, step 30: 4.790801\n",
      "Average train loss at epoch 0, step 60: 2.904990\n",
      "Average train loss at epoch 0, step 90: 2.650847\n",
      "Average train loss at epoch 0, step 120: 2.308156\n",
      "Average train loss at epoch 0, step 150: 2.325435\n",
      "Average train loss at epoch 0, step 180: 2.133970\n",
      "Average train loss at epoch 0, step 210: 1.873107\n",
      "Average train loss at epoch 0, step 240: 1.940194\n",
      "Average train loss at epoch 0, step 270: 1.659800\n",
      "[Epoch 0] Average train loss: 2.4973366937756967\n",
      "Input Sentence        :  ['from', 'philadelphia', 'to', 'toronto', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'B-toloc.city_name', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.7722222222222223, intent accuracy: 0.875\n",
      "slot accuracy: 0.8289473684210527, intent accuracy: 0.875\n",
      "slot accuracy: 0.8303030303030303, intent accuracy: 1.0\n",
      "slot accuracy: 0.7577319587628866, intent accuracy: 0.875\n",
      "slot accuracy: 0.7722222222222223, intent accuracy: 0.875\n",
      "slot accuracy: 0.7965116279069767, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8407643312101911, intent accuracy: 0.625\n",
      "slot accuracy: 0.8070175438596491, intent accuracy: 0.9375\n",
      "slot accuracy: 0.717948717948718, intent accuracy: 0.625\n",
      "slot accuracy: 0.8095238095238095, intent accuracy: 0.9375\n",
      "slot accuracy: 0.7376237623762376, intent accuracy: 0.6875\n",
      "slot accuracy: 0.7926267281105991, intent accuracy: 0.9375\n",
      "slot accuracy: 0.7541899441340782, intent accuracy: 0.75\n",
      "slot accuracy: 0.7696969696969697, intent accuracy: 0.875\n",
      "slot accuracy: 0.7227722772277227, intent accuracy: 0.9375\n",
      "slot accuracy: 0.7261146496815286, intent accuracy: 0.75\n",
      "slot accuracy: 0.7731958762886598, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7580645161290323, intent accuracy: 0.625\n",
      "slot accuracy: 0.7783783783783784, intent accuracy: 0.75\n",
      "slot accuracy: 0.7108433734939759, intent accuracy: 0.75\n",
      "slot accuracy: 0.76875, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7692307692307693, intent accuracy: 0.9375\n",
      "slot accuracy: 0.7978142076502732, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7513812154696132, intent accuracy: 0.6875\n",
      "slot accuracy: 0.7873563218390804, intent accuracy: 0.875\n",
      "slot accuracy: 0.7789473684210526, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7172995780590717, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7604166666666666, intent accuracy: 0.875\n",
      "slot accuracy: 0.8144329896907216, intent accuracy: 0.8125\n",
      "slot accuracy: 0.7674418604651163, intent accuracy: 0.75\n",
      "slot accuracy: 0.7888198757763976, intent accuracy: 0.75\n",
      "F1 score for epoch 0: 0.7713932107496464\n",
      "Average train loss at epoch 1, step 0: 1.815499\n",
      "Average train loss at epoch 1, step 30: 1.494896\n",
      "Average train loss at epoch 1, step 60: 1.470006\n",
      "Average train loss at epoch 1, step 90: 1.268454\n",
      "Average train loss at epoch 1, step 120: 1.301602\n",
      "Average train loss at epoch 1, step 150: 1.278197\n",
      "Average train loss at epoch 1, step 180: 1.194723\n",
      "Average train loss at epoch 1, step 210: 1.050673\n",
      "Average train loss at epoch 1, step 240: 1.063741\n",
      "Average train loss at epoch 1, step 270: 1.072238\n",
      "[Epoch 1] Average train loss: 1.241209518738545\n",
      "Input Sentence        :  ['what', 'flights', 'leave', 'la', 'guardia', 'for', 'san', 'jose', 'and', 'arrive', '10', 'pm', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'B-fromloc.airport_name', 'I-fromloc.airport_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'O', 'B-arrive_time.time', 'I-arrive_time.time', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'I-fromloc.city_name', 'O', 'O', 'I-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-arrive_time.time_relative', 'B-arrive_time.time', 'I-arrive_time.time', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.8353658536585366, intent accuracy: 1.0\n",
      "slot accuracy: 0.8367346938775511, intent accuracy: 0.75\n",
      "slot accuracy: 0.8994708994708994, intent accuracy: 0.875\n",
      "slot accuracy: 0.8220858895705522, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8131313131313131, intent accuracy: 0.9375\n",
      "slot accuracy: 0.819672131147541, intent accuracy: 0.875\n",
      "slot accuracy: 0.8409090909090909, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8539325842696629, intent accuracy: 0.875\n",
      "slot accuracy: 0.8109756097560976, intent accuracy: 0.75\n",
      "slot accuracy: 0.8102564102564103, intent accuracy: 1.0\n",
      "slot accuracy: 0.863905325443787, intent accuracy: 1.0\n",
      "slot accuracy: 0.8308457711442786, intent accuracy: 1.0\n",
      "slot accuracy: 0.8084112149532711, intent accuracy: 0.875\n",
      "slot accuracy: 0.7970297029702971, intent accuracy: 0.75\n",
      "slot accuracy: 0.7912087912087912, intent accuracy: 1.0\n",
      "slot accuracy: 0.8466666666666667, intent accuracy: 0.875\n",
      "slot accuracy: 0.8021390374331551, intent accuracy: 0.875\n",
      "slot accuracy: 0.8414634146341463, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8061224489795918, intent accuracy: 0.75\n",
      "slot accuracy: 0.8121546961325967, intent accuracy: 0.8125\n",
      "slot accuracy: 0.774390243902439, intent accuracy: 0.75\n",
      "slot accuracy: 0.8048780487804879, intent accuracy: 1.0\n",
      "slot accuracy: 0.8333333333333334, intent accuracy: 1.0\n",
      "slot accuracy: 0.8661971830985915, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8564593301435407, intent accuracy: 0.875\n",
      "slot accuracy: 0.8260869565217391, intent accuracy: 0.875\n",
      "slot accuracy: 0.8471337579617835, intent accuracy: 0.875\n",
      "slot accuracy: 0.8258928571428571, intent accuracy: 0.875\n",
      "slot accuracy: 0.7239583333333334, intent accuracy: 0.875\n",
      "slot accuracy: 0.8210526315789474, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8131313131313131, intent accuracy: 0.8125\n",
      "F1 score for epoch 1: 0.8227602049832126\n",
      "Average train loss at epoch 2, step 0: 0.469329\n",
      "Average train loss at epoch 2, step 30: 0.808635\n",
      "Average train loss at epoch 2, step 60: 0.860381\n",
      "Average train loss at epoch 2, step 90: 0.823707\n",
      "Average train loss at epoch 2, step 120: 0.837988\n",
      "Average train loss at epoch 2, step 150: 0.820485\n",
      "Average train loss at epoch 2, step 180: 0.814552\n",
      "Average train loss at epoch 2, step 210: 0.756736\n",
      "Average train loss at epoch 2, step 240: 0.758249\n",
      "Average train loss at epoch 2, step 270: 0.596526\n",
      "[Epoch 2] Average train loss: 0.7816346391341165\n",
      "Input Sentence        :  ['shortest', 'flights', 'from', 'nashville', 'to', 'st.', 'petersburg', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['B-flight_mod', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'B-depart_date.day_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.868421052631579, intent accuracy: 1.0\n",
      "slot accuracy: 0.930635838150289, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8930232558139535, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8930817610062893, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9157303370786517, intent accuracy: 1.0\n",
      "slot accuracy: 0.7894736842105263, intent accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot accuracy: 0.8735632183908046, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9456521739130435, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8578947368421053, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9025974025974026, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8928571428571429, intent accuracy: 0.875\n",
      "slot accuracy: 0.9033816425120773, intent accuracy: 1.0\n",
      "slot accuracy: 0.9141104294478528, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8789808917197452, intent accuracy: 1.0\n",
      "slot accuracy: 0.9385474860335196, intent accuracy: 1.0\n",
      "slot accuracy: 0.8755980861244019, intent accuracy: 1.0\n",
      "slot accuracy: 0.8461538461538461, intent accuracy: 1.0\n",
      "slot accuracy: 0.9411764705882353, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8723404255319149, intent accuracy: 1.0\n",
      "slot accuracy: 0.8941176470588236, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8670212765957447, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8764044943820225, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8666666666666667, intent accuracy: 0.8125\n",
      "slot accuracy: 0.859375, intent accuracy: 0.9375\n",
      "slot accuracy: 0.85, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8653846153846154, intent accuracy: 0.9375\n",
      "slot accuracy: 0.89937106918239, intent accuracy: 0.8125\n",
      "slot accuracy: 0.865979381443299, intent accuracy: 0.875\n",
      "slot accuracy: 0.8669950738916257, intent accuracy: 1.0\n",
      "slot accuracy: 0.8666666666666667, intent accuracy: 1.0\n",
      "slot accuracy: 0.9, intent accuracy: 1.0\n",
      "F1 score for epoch 2: 0.883622214361514\n",
      "Average train loss at epoch 3, step 0: 0.348451\n",
      "Average train loss at epoch 3, step 30: 0.572141\n",
      "Average train loss at epoch 3, step 60: 0.580900\n",
      "Average train loss at epoch 3, step 90: 0.520374\n",
      "Average train loss at epoch 3, step 120: 0.505972\n",
      "Average train loss at epoch 3, step 150: 0.517561\n",
      "Average train loss at epoch 3, step 180: 0.512962\n",
      "Average train loss at epoch 3, step 210: 0.506539\n",
      "Average train loss at epoch 3, step 240: 0.533412\n",
      "Average train loss at epoch 3, step 270: 0.471074\n",
      "[Epoch 3] Average train loss: 0.5253516803078326\n",
      "Input Sentence        :  ['what', 'types', 'of', 'ground', 'transportation', 'are', 'available', 'in', 'philadelphia', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-city_name', 'I-airport_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_ground_service\n",
      "Intent Prediction     :  atis_ground_service\n",
      "slot accuracy: 0.9010416666666666, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9430051813471503, intent accuracy: 0.875\n",
      "slot accuracy: 0.9479768786127167, intent accuracy: 0.875\n",
      "slot accuracy: 0.9234449760765551, intent accuracy: 1.0\n",
      "slot accuracy: 0.8653846153846154, intent accuracy: 0.875\n",
      "slot accuracy: 0.9133333333333333, intent accuracy: 0.8125\n",
      "slot accuracy: 0.8928571428571429, intent accuracy: 1.0\n",
      "slot accuracy: 0.8928571428571429, intent accuracy: 0.875\n",
      "slot accuracy: 0.95, intent accuracy: 1.0\n",
      "slot accuracy: 0.9273743016759777, intent accuracy: 1.0\n",
      "slot accuracy: 0.9135135135135135, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9364161849710982, intent accuracy: 0.875\n",
      "slot accuracy: 0.9523809523809523, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9257142857142857, intent accuracy: 1.0\n",
      "slot accuracy: 0.9441340782122905, intent accuracy: 1.0\n",
      "slot accuracy: 0.8974358974358975, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8941798941798942, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8970588235294118, intent accuracy: 0.9375\n",
      "slot accuracy: 0.937888198757764, intent accuracy: 1.0\n",
      "slot accuracy: 0.9141104294478528, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9427083333333334, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9105263157894737, intent accuracy: 0.875\n",
      "slot accuracy: 0.9202127659574468, intent accuracy: 1.0\n",
      "slot accuracy: 0.9461077844311377, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9107142857142857, intent accuracy: 1.0\n",
      "slot accuracy: 0.8936170212765957, intent accuracy: 0.875\n",
      "slot accuracy: 0.9052132701421801, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9166666666666666, intent accuracy: 1.0\n",
      "slot accuracy: 0.945054945054945, intent accuracy: 1.0\n",
      "slot accuracy: 0.9294117647058824, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8768472906403941, intent accuracy: 0.9375\n",
      "F1 score for epoch 3: 0.9172998763032338\n",
      "Average train loss at epoch 4, step 0: 0.340421\n",
      "Average train loss at epoch 4, step 30: 0.320355\n",
      "Average train loss at epoch 4, step 60: 0.389206\n",
      "Average train loss at epoch 4, step 90: 0.369355\n",
      "Average train loss at epoch 4, step 120: 0.372275\n",
      "Average train loss at epoch 4, step 150: 0.378458\n",
      "Average train loss at epoch 4, step 180: 0.342382\n",
      "Average train loss at epoch 4, step 210: 0.367239\n",
      "Average train loss at epoch 4, step 240: 0.331243\n",
      "Average train loss at epoch 4, step 270: 0.331761\n",
      "[Epoch 4] Average train loss: 0.3519505881654319\n",
      "Input Sentence        :  ['newark', 'to', 'cleveland', 'daily', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-flight_days', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-depart_date.day_name', 'B-depart_time.time_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9298245614035088, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9028571428571428, intent accuracy: 1.0\n",
      "slot accuracy: 0.9408284023668639, intent accuracy: 1.0\n",
      "slot accuracy: 0.9315068493150684, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9006211180124224, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9367816091954023, intent accuracy: 1.0\n",
      "slot accuracy: 0.9408866995073891, intent accuracy: 1.0\n",
      "slot accuracy: 0.9065934065934066, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9257425742574258, intent accuracy: 1.0\n",
      "slot accuracy: 0.9340659340659341, intent accuracy: 1.0\n",
      "slot accuracy: 0.9536082474226805, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9518072289156626, intent accuracy: 1.0\n",
      "slot accuracy: 0.9117647058823529, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9340659340659341, intent accuracy: 1.0\n",
      "slot accuracy: 0.9732620320855615, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9365079365079365, intent accuracy: 0.9375\n",
      "slot accuracy: 0.975, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9457831325301205, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9468085106382979, intent accuracy: 1.0\n",
      "slot accuracy: 0.9888888888888889, intent accuracy: 1.0\n",
      "slot accuracy: 0.9444444444444444, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9516129032258065, intent accuracy: 1.0\n",
      "slot accuracy: 0.9253731343283582, intent accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot accuracy: 0.936046511627907, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9272727272727272, intent accuracy: 1.0\n",
      "slot accuracy: 0.9217877094972067, intent accuracy: 1.0\n",
      "slot accuracy: 0.9082125603864735, intent accuracy: 0.875\n",
      "slot accuracy: 0.93125, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9526627218934911, intent accuracy: 1.0\n",
      "slot accuracy: 0.9593023255813954, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9565217391304348, intent accuracy: 0.9375\n",
      "F1 score for epoch 4: 0.9380843182219086\n",
      "Average train loss at epoch 5, step 0: 0.483348\n",
      "Average train loss at epoch 5, step 30: 0.262663\n",
      "Average train loss at epoch 5, step 60: 0.266014\n",
      "Average train loss at epoch 5, step 90: 0.268306\n",
      "Average train loss at epoch 5, step 120: 0.207508\n",
      "Average train loss at epoch 5, step 150: 0.240003\n",
      "Average train loss at epoch 5, step 180: 0.242127\n",
      "Average train loss at epoch 5, step 210: 0.225100\n",
      "Average train loss at epoch 5, step 240: 0.244754\n",
      "Average train loss at epoch 5, step 270: 0.280106\n",
      "[Epoch 5] Average train loss: 0.25317812570801346\n",
      "Input Sentence        :  ['what', 'first', 'class', 'flights', 'are', 'available', 'on', 'july', 'twenty', 'fifth', '1991', 'from', 'denver', 'to', 'baltimore', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'B-class_type', 'I-class_type', 'O', 'O', 'O', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'I-depart_date.day_number', 'B-depart_date.year', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'B-class_type', 'I-class_type', 'O', 'O', 'O', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'I-depart_date.day_number', 'B-depart_date.year', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-depart_time.time_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9351851851851852, intent accuracy: 1.0\n",
      "slot accuracy: 0.9719101123595506, intent accuracy: 1.0\n",
      "slot accuracy: 0.9588235294117647, intent accuracy: 0.9375\n",
      "slot accuracy: 0.8876404494382022, intent accuracy: 0.9375\n",
      "slot accuracy: 0.946524064171123, intent accuracy: 1.0\n",
      "slot accuracy: 0.9175824175824175, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9341317365269461, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9381443298969072, intent accuracy: 1.0\n",
      "slot accuracy: 0.9858156028368794, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9214659685863874, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9384615384615385, intent accuracy: 1.0\n",
      "slot accuracy: 0.9264705882352942, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9586206896551724, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9392265193370166, intent accuracy: 0.875\n",
      "slot accuracy: 0.9395973154362416, intent accuracy: 1.0\n",
      "slot accuracy: 0.9523809523809523, intent accuracy: 1.0\n",
      "slot accuracy: 0.94375, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9695431472081218, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9248826291079812, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9521276595744681, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9415204678362573, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9487179487179487, intent accuracy: 1.0\n",
      "slot accuracy: 0.96045197740113, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9301075268817204, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9607843137254902, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9162995594713657, intent accuracy: 1.0\n",
      "slot accuracy: 0.9526315789473684, intent accuracy: 0.9375\n",
      "slot accuracy: 0.921875, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9569377990430622, intent accuracy: 1.0\n",
      "slot accuracy: 0.8882978723404256, intent accuracy: 0.9375\n",
      "slot accuracy: 0.953757225433526, intent accuracy: 0.8125\n",
      "F1 score for epoch 5: 0.9401588702559577\n",
      "Average train loss at epoch 6, step 0: 0.288778\n",
      "Average train loss at epoch 6, step 30: 0.193669\n",
      "Average train loss at epoch 6, step 60: 0.181096\n",
      "Average train loss at epoch 6, step 90: 0.174224\n",
      "Average train loss at epoch 6, step 120: 0.190838\n",
      "Average train loss at epoch 6, step 150: 0.228488\n",
      "Average train loss at epoch 6, step 180: 0.207504\n",
      "Average train loss at epoch 6, step 210: 0.177495\n",
      "Average train loss at epoch 6, step 240: 0.181119\n",
      "Average train loss at epoch 6, step 270: 0.154087\n",
      "[Epoch 6] Average train loss: 0.188890199667664\n",
      "Input Sentence        :  ['give', 'me', 'flights', 'from', 'denver', 'to', 'baltimore', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-depart_date.today_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9944444444444445, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9717514124293786, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9487179487179487, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9263803680981595, intent accuracy: 1.0\n",
      "slot accuracy: 0.9588235294117647, intent accuracy: 1.0\n",
      "slot accuracy: 0.9246231155778895, intent accuracy: 1.0\n",
      "slot accuracy: 0.9536082474226805, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9666666666666667, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9555555555555556, intent accuracy: 1.0\n",
      "slot accuracy: 0.9333333333333333, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9506726457399103, intent accuracy: 1.0\n",
      "slot accuracy: 0.9606741573033708, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9583333333333334, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9337016574585635, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9393939393939394, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9659863945578231, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9640718562874252, intent accuracy: 0.9375\n",
      "slot accuracy: 0.95, intent accuracy: 1.0\n",
      "slot accuracy: 0.9795918367346939, intent accuracy: 1.0\n",
      "slot accuracy: 0.9611111111111111, intent accuracy: 1.0\n",
      "slot accuracy: 0.9850746268656716, intent accuracy: 1.0\n",
      "slot accuracy: 0.9351351351351351, intent accuracy: 0.875\n",
      "slot accuracy: 0.9612903225806452, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9625668449197861, intent accuracy: 1.0\n",
      "slot accuracy: 0.9615384615384616, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9629629629629629, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9593023255813954, intent accuracy: 1.0\n",
      "slot accuracy: 0.9770114942528736, intent accuracy: 1.0\n",
      "slot accuracy: 0.949685534591195, intent accuracy: 1.0\n",
      "slot accuracy: 0.943502824858757, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9430051813471503, intent accuracy: 1.0\n",
      "F1 score for epoch 6: 0.9561908133463138\n",
      "Average train loss at epoch 7, step 0: 0.211128\n",
      "Average train loss at epoch 7, step 30: 0.150549\n",
      "Average train loss at epoch 7, step 60: 0.157068\n",
      "Average train loss at epoch 7, step 90: 0.142416\n",
      "Average train loss at epoch 7, step 120: 0.146164\n",
      "Average train loss at epoch 7, step 150: 0.188824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train loss at epoch 7, step 180: 0.183308\n",
      "Average train loss at epoch 7, step 210: 0.170131\n",
      "Average train loss at epoch 7, step 240: 0.136500\n",
      "Average train loss at epoch 7, step 270: 0.129970\n",
      "[Epoch 7] Average train loss: 0.15683271004200836\n",
      "Input Sentence        :  ['show', 'me', 'all', 'united', 'flights', 'from', 'denver', 'to', 'san', 'francisco', 'for', 'september', 'first', '1991', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'B-airline_name', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'B-depart_date.year', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'B-airline_name', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'B-depart_date.year', 'B-depart_date.today_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9484536082474226, intent accuracy: 1.0\n",
      "slot accuracy: 0.9845360824742269, intent accuracy: 1.0\n",
      "slot accuracy: 0.9775280898876404, intent accuracy: 1.0\n",
      "slot accuracy: 0.9128440366972477, intent accuracy: 1.0\n",
      "slot accuracy: 0.9339622641509434, intent accuracy: 1.0\n",
      "slot accuracy: 0.9621621621621622, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9781420765027322, intent accuracy: 0.875\n",
      "slot accuracy: 0.9560439560439561, intent accuracy: 1.0\n",
      "slot accuracy: 0.9405405405405406, intent accuracy: 1.0\n",
      "slot accuracy: 0.979381443298969, intent accuracy: 1.0\n",
      "slot accuracy: 0.9719626168224299, intent accuracy: 1.0\n",
      "slot accuracy: 0.8944099378881988, intent accuracy: 1.0\n",
      "slot accuracy: 0.949685534591195, intent accuracy: 1.0\n",
      "slot accuracy: 0.9526627218934911, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9751552795031055, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9888888888888889, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9725274725274725, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9389671361502347, intent accuracy: 1.0\n",
      "slot accuracy: 0.9408602150537635, intent accuracy: 0.875\n",
      "slot accuracy: 0.9132947976878613, intent accuracy: 1.0\n",
      "slot accuracy: 0.9904761904761905, intent accuracy: 1.0\n",
      "slot accuracy: 0.9641025641025641, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9717514124293786, intent accuracy: 1.0\n",
      "slot accuracy: 0.9759036144578314, intent accuracy: 1.0\n",
      "slot accuracy: 0.9720670391061452, intent accuracy: 0.9375\n",
      "slot accuracy: 0.935, intent accuracy: 0.875\n",
      "slot accuracy: 0.9479768786127167, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9640718562874252, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9875776397515528, intent accuracy: 0.875\n",
      "slot accuracy: 0.9717514124293786, intent accuracy: 1.0\n",
      "slot accuracy: 0.950354609929078, intent accuracy: 1.0\n",
      "F1 score for epoch 7: 0.9581863091037403\n",
      "Average train loss at epoch 8, step 0: 0.094794\n",
      "Average train loss at epoch 8, step 30: 0.129413\n",
      "Average train loss at epoch 8, step 60: 0.096087\n",
      "Average train loss at epoch 8, step 90: 0.113835\n",
      "Average train loss at epoch 8, step 120: 0.103842\n",
      "Average train loss at epoch 8, step 150: 0.113571\n",
      "Average train loss at epoch 8, step 180: 0.107639\n",
      "Average train loss at epoch 8, step 210: 0.101604\n",
      "Average train loss at epoch 8, step 240: 0.109077\n",
      "Average train loss at epoch 8, step 270: 0.101452\n",
      "[Epoch 8] Average train loss: 0.1094050602052748\n",
      "Input Sentence        :  ['what', 'ground', 'transportation', 'is', 'available', 'in', 'denver', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'O', 'B-city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'B-city_name', 'B-state_code', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_ground_service\n",
      "Intent Prediction     :  atis_ground_service\n",
      "slot accuracy: 0.9837837837837838, intent accuracy: 1.0\n",
      "slot accuracy: 0.9833333333333333, intent accuracy: 1.0\n",
      "slot accuracy: 0.9659090909090909, intent accuracy: 1.0\n",
      "slot accuracy: 0.9230769230769231, intent accuracy: 0.875\n",
      "slot accuracy: 0.978494623655914, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9675324675324676, intent accuracy: 1.0\n",
      "slot accuracy: 0.9940119760479041, intent accuracy: 1.0\n",
      "slot accuracy: 0.9702380952380952, intent accuracy: 1.0\n",
      "slot accuracy: 0.9725274725274725, intent accuracy: 1.0\n",
      "slot accuracy: 0.9216589861751152, intent accuracy: 1.0\n",
      "slot accuracy: 0.956989247311828, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9819277108433735, intent accuracy: 1.0\n",
      "slot accuracy: 0.9395604395604396, intent accuracy: 0.875\n",
      "slot accuracy: 0.9453551912568307, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9581151832460733, intent accuracy: 1.0\n",
      "slot accuracy: 0.9939024390243902, intent accuracy: 1.0\n",
      "slot accuracy: 0.9800995024875622, intent accuracy: 1.0\n",
      "slot accuracy: 0.9479166666666666, intent accuracy: 0.875\n",
      "slot accuracy: 0.9732620320855615, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9579439252336449, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9879518072289156, intent accuracy: 1.0\n",
      "slot accuracy: 0.9529914529914529, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9646464646464646, intent accuracy: 1.0\n",
      "slot accuracy: 0.9382022471910112, intent accuracy: 1.0\n",
      "slot accuracy: 0.96, intent accuracy: 1.0\n",
      "slot accuracy: 0.9532163742690059, intent accuracy: 1.0\n",
      "slot accuracy: 0.9829545454545454, intent accuracy: 1.0\n",
      "slot accuracy: 0.9512195121951219, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9823529411764705, intent accuracy: 0.875\n",
      "slot accuracy: 0.9840425531914894, intent accuracy: 1.0\n",
      "slot accuracy: 0.9651162790697675, intent accuracy: 1.0\n",
      "F1 score for epoch 8: 0.9646268128758402\n",
      "Average train loss at epoch 9, step 0: 0.038070\n",
      "Average train loss at epoch 9, step 30: 0.090050\n",
      "Average train loss at epoch 9, step 60: 0.097712\n",
      "Average train loss at epoch 9, step 90: 0.094118\n",
      "Average train loss at epoch 9, step 120: 0.089463\n",
      "Average train loss at epoch 9, step 150: 0.090900\n",
      "Average train loss at epoch 9, step 180: 0.097900\n",
      "Average train loss at epoch 9, step 210: 0.084798\n",
      "Average train loss at epoch 9, step 240: 0.087108\n",
      "Average train loss at epoch 9, step 270: 0.082264\n",
      "[Epoch 9] Average train loss: 0.09188176417810089\n",
      "Input Sentence        :  ['how', 'many', 'flights', 'does', 'each', 'airline', 'have', 'with', 'booking', 'class', '<UNK>', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fare_basis_code', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-depart_date.today_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_quantity\n",
      "Intent Prediction     :  atis_quantity\n",
      "slot accuracy: 0.9754601226993865, intent accuracy: 1.0\n",
      "slot accuracy: 0.9595375722543352, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9685534591194969, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9612903225806452, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9739583333333334, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9363057324840764, intent accuracy: 0.875\n",
      "slot accuracy: 0.9881656804733728, intent accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot accuracy: 0.9760479041916168, intent accuracy: 0.9375\n",
      "slot accuracy: 0.943127962085308, intent accuracy: 1.0\n",
      "slot accuracy: 0.9886363636363636, intent accuracy: 1.0\n",
      "slot accuracy: 0.9747474747474747, intent accuracy: 1.0\n",
      "slot accuracy: 0.9649122807017544, intent accuracy: 0.875\n",
      "slot accuracy: 0.9876543209876543, intent accuracy: 1.0\n",
      "slot accuracy: 0.9822485207100592, intent accuracy: 1.0\n",
      "slot accuracy: 0.9552238805970149, intent accuracy: 1.0\n",
      "slot accuracy: 0.9842931937172775, intent accuracy: 1.0\n",
      "slot accuracy: 1.0, intent accuracy: 1.0\n",
      "slot accuracy: 0.956989247311828, intent accuracy: 1.0\n",
      "slot accuracy: 0.9782608695652174, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9701492537313433, intent accuracy: 1.0\n",
      "slot accuracy: 0.9488636363636364, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9203980099502488, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9681528662420382, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9722222222222222, intent accuracy: 1.0\n",
      "slot accuracy: 0.9368421052631579, intent accuracy: 0.9375\n",
      "slot accuracy: 0.95260663507109, intent accuracy: 1.0\n",
      "slot accuracy: 0.9396984924623115, intent accuracy: 1.0\n",
      "slot accuracy: 0.9712643678160919, intent accuracy: 1.0\n",
      "slot accuracy: 0.958974358974359, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9696969696969697, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9239130434782609, intent accuracy: 1.0\n",
      "F1 score for epoch 9: 0.9638021063810956\n",
      "Average train loss at epoch 10, step 0: 0.013238\n",
      "Average train loss at epoch 10, step 30: 0.060463\n",
      "Average train loss at epoch 10, step 60: 0.077368\n",
      "Average train loss at epoch 10, step 90: 0.063706\n",
      "Average train loss at epoch 10, step 120: 0.055138\n",
      "Average train loss at epoch 10, step 150: 0.055317\n",
      "Average train loss at epoch 10, step 180: 0.067882\n",
      "Average train loss at epoch 10, step 210: 0.071959\n",
      "Average train loss at epoch 10, step 240: 0.074458\n",
      "Average train loss at epoch 10, step 270: 0.077809\n",
      "[Epoch 10] Average train loss: 0.06678616114655063\n",
      "Input Sentence        :  ['i', 'would', 'like', 'to', 'find', 'a', 'flight', 'that', 'goes', 'from', 'tampa', 'to', 'montreal', 'making', 'a', 'stop', 'in', 'new', 'york', 'and', 'a', 'flight', 'that', 'serves', 'lunch', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-meal_description', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'O', 'O', 'O', 'O', 'B-stoploc.city_name', 'I-stoploc.city_name', 'O', 'O', 'O', 'O', 'O', 'B-meal_description', 'B-meal_description', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9809523809523809, intent accuracy: 1.0\n",
      "slot accuracy: 0.9946808510638298, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9367088607594937, intent accuracy: 1.0\n",
      "slot accuracy: 0.9884393063583815, intent accuracy: 1.0\n",
      "slot accuracy: 0.9844559585492227, intent accuracy: 1.0\n",
      "slot accuracy: 0.9368932038834952, intent accuracy: 1.0\n",
      "slot accuracy: 0.9620253164556962, intent accuracy: 1.0\n",
      "slot accuracy: 0.9518716577540107, intent accuracy: 1.0\n",
      "slot accuracy: 0.9880952380952381, intent accuracy: 1.0\n",
      "slot accuracy: 0.9209486166007905, intent accuracy: 1.0\n",
      "slot accuracy: 0.979381443298969, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9351851851851852, intent accuracy: 0.9375\n",
      "slot accuracy: 1.0, intent accuracy: 1.0\n",
      "slot accuracy: 0.9575757575757575, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9759036144578314, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9540229885057471, intent accuracy: 1.0\n",
      "slot accuracy: 0.9888888888888889, intent accuracy: 1.0\n",
      "slot accuracy: 0.9772727272727273, intent accuracy: 1.0\n",
      "slot accuracy: 0.9607843137254902, intent accuracy: 1.0\n",
      "slot accuracy: 0.9931972789115646, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9754601226993865, intent accuracy: 1.0\n",
      "slot accuracy: 0.9574468085106383, intent accuracy: 1.0\n",
      "slot accuracy: 0.9942196531791907, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9728260869565217, intent accuracy: 0.875\n",
      "slot accuracy: 0.950920245398773, intent accuracy: 0.875\n",
      "slot accuracy: 0.9774011299435028, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9627329192546584, intent accuracy: 0.875\n",
      "slot accuracy: 0.9390862944162437, intent accuracy: 1.0\n",
      "slot accuracy: 0.9887640449438202, intent accuracy: 1.0\n",
      "slot accuracy: 0.9674418604651163, intent accuracy: 0.875\n",
      "slot accuracy: 0.994475138121547, intent accuracy: 0.9375\n",
      "F1 score for epoch 10: 0.9683225977234624\n",
      "Average train loss at epoch 11, step 0: 0.035908\n",
      "Average train loss at epoch 11, step 30: 0.057114\n",
      "Average train loss at epoch 11, step 60: 0.049158\n",
      "Average train loss at epoch 11, step 90: 0.045989\n",
      "Average train loss at epoch 11, step 120: 0.042086\n",
      "Average train loss at epoch 11, step 150: 0.066107\n",
      "Average train loss at epoch 11, step 180: 0.060948\n",
      "Average train loss at epoch 11, step 210: 0.057686\n",
      "Average train loss at epoch 11, step 240: 0.046772\n",
      "Average train loss at epoch 11, step 270: 0.056107\n",
      "[Epoch 11] Average train loss: 0.053093673153963995\n",
      "Input Sentence        :  ['show', 'me', 'flights', 'from', 'atlanta', 'to', 'baltimore', 'denver', 'and', 'dallas', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-toloc.city_name', 'O', 'B-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-fromloc.city_name', 'O', 'B-fromloc.city_name', 'B-depart_time.time_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_flight\n",
      "Intent Prediction     :  atis_flight\n",
      "slot accuracy: 0.9662921348314607, intent accuracy: 1.0\n",
      "slot accuracy: 0.9431818181818182, intent accuracy: 0.875\n",
      "slot accuracy: 0.9529411764705882, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9567307692307693, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9836065573770492, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9428571428571428, intent accuracy: 1.0\n",
      "slot accuracy: 1.0, intent accuracy: 1.0\n",
      "slot accuracy: 0.9682539682539683, intent accuracy: 1.0\n",
      "slot accuracy: 0.9476190476190476, intent accuracy: 1.0\n",
      "slot accuracy: 0.9820359281437125, intent accuracy: 1.0\n",
      "slot accuracy: 0.9483568075117371, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9675675675675676, intent accuracy: 0.9375\n",
      "slot accuracy: 0.976878612716763, intent accuracy: 1.0\n",
      "slot accuracy: 0.9728260869565217, intent accuracy: 0.9375\n",
      "slot accuracy: 0.983957219251337, intent accuracy: 1.0\n",
      "slot accuracy: 0.9891304347826086, intent accuracy: 1.0\n",
      "slot accuracy: 0.9536423841059603, intent accuracy: 1.0\n",
      "slot accuracy: 0.9828571428571429, intent accuracy: 1.0\n",
      "slot accuracy: 0.9441624365482234, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9855769230769231, intent accuracy: 1.0\n",
      "slot accuracy: 0.9572192513368984, intent accuracy: 1.0\n",
      "slot accuracy: 0.9728260869565217, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9705882352941176, intent accuracy: 1.0\n",
      "slot accuracy: 0.9759036144578314, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9887005649717514, intent accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot accuracy: 0.967741935483871, intent accuracy: 0.9375\n",
      "slot accuracy: 1.0, intent accuracy: 1.0\n",
      "slot accuracy: 0.9696969696969697, intent accuracy: 1.0\n",
      "slot accuracy: 0.9555555555555556, intent accuracy: 1.0\n",
      "slot accuracy: 0.9896373056994818, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9722222222222222, intent accuracy: 0.875\n",
      "F1 score for epoch 11: 0.9695736776932602\n",
      "Average train loss at epoch 12, step 0: 0.027130\n",
      "Average train loss at epoch 12, step 30: 0.033705\n",
      "Average train loss at epoch 12, step 60: 0.050137\n",
      "Average train loss at epoch 12, step 90: 0.042023\n",
      "Average train loss at epoch 12, step 120: 0.037505\n",
      "Average train loss at epoch 12, step 150: 0.032571\n",
      "Average train loss at epoch 12, step 180: 0.036786\n",
      "Average train loss at epoch 12, step 210: 0.039579\n",
      "Average train loss at epoch 12, step 240: 0.034880\n",
      "Average train loss at epoch 12, step 270: 0.055085\n",
      "[Epoch 12] Average train loss: 0.04075843524221184\n",
      "Input Sentence        :  ['what', 'kind', 'of', 'aircraft', 'does', 'delta', 'fly', 'before', '8', 'am', 'on', 'august', 'second', 'from', 'boston', 'to', 'denver', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'B-airline_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'I-depart_time.time', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'B-airline_name', 'O', 'B-depart_time.time_relative', 'B-depart_time.time', 'I-depart_time.time', 'O', 'B-depart_date.month_name', 'B-depart_date.day_number', 'O', 'B-fromloc.city_name', 'O', 'B-toloc.city_name', 'B-depart_date.day_name', '<PAD>']\n",
      "Intent Truth          :  atis_aircraft\n",
      "Intent Prediction     :  atis_aircraft\n",
      "slot accuracy: 0.9880239520958084, intent accuracy: 1.0\n",
      "slot accuracy: 0.9588235294117647, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9840425531914894, intent accuracy: 1.0\n",
      "slot accuracy: 0.9639175257731959, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9572192513368984, intent accuracy: 1.0\n",
      "slot accuracy: 0.9885714285714285, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9289099526066351, intent accuracy: 1.0\n",
      "slot accuracy: 0.9782608695652174, intent accuracy: 1.0\n",
      "slot accuracy: 1.0, intent accuracy: 1.0\n",
      "slot accuracy: 0.9717514124293786, intent accuracy: 0.875\n",
      "slot accuracy: 0.9624413145539906, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9761904761904762, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9704142011834319, intent accuracy: 1.0\n",
      "slot accuracy: 0.9758454106280193, intent accuracy: 1.0\n",
      "slot accuracy: 0.9672131147540983, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9635416666666666, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9901477832512315, intent accuracy: 0.9375\n",
      "slot accuracy: 1.0, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9690721649484536, intent accuracy: 1.0\n",
      "slot accuracy: 0.9764705882352941, intent accuracy: 1.0\n",
      "slot accuracy: 0.9890710382513661, intent accuracy: 1.0\n",
      "slot accuracy: 0.971830985915493, intent accuracy: 0.875\n",
      "slot accuracy: 0.8789473684210526, intent accuracy: 1.0\n",
      "slot accuracy: 0.9827586206896551, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9672131147540983, intent accuracy: 0.875\n",
      "slot accuracy: 0.9485714285714286, intent accuracy: 1.0\n",
      "slot accuracy: 0.9715639810426541, intent accuracy: 1.0\n",
      "slot accuracy: 0.9942857142857143, intent accuracy: 1.0\n",
      "slot accuracy: 0.9080459770114943, intent accuracy: 1.0\n",
      "slot accuracy: 0.9715909090909091, intent accuracy: 1.0\n",
      "slot accuracy: 0.9560975609756097, intent accuracy: 1.0\n",
      "F1 score for epoch 12: 0.9676052608350253\n",
      "Average train loss at epoch 13, step 0: 0.020462\n",
      "Average train loss at epoch 13, step 30: 0.031460\n",
      "Average train loss at epoch 13, step 60: 0.029162\n",
      "Average train loss at epoch 13, step 90: 0.035419\n",
      "Average train loss at epoch 13, step 120: 0.034897\n",
      "Average train loss at epoch 13, step 150: 0.025478\n",
      "Average train loss at epoch 13, step 180: 0.028226\n",
      "Average train loss at epoch 13, step 210: 0.022354\n",
      "Average train loss at epoch 13, step 240: 0.044163\n",
      "Average train loss at epoch 13, step 270: 0.032853\n",
      "[Epoch 13] Average train loss: 0.031544873965770596\n",
      "Input Sentence        :  ['how', 'many', 'flights', 'does', 'each', 'airline', 'have', 'with', 'booking', 'class', '<UNK>', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-fare_basis_code', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-flight_number', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_quantity\n",
      "Intent Prediction     :  atis_quantity\n",
      "slot accuracy: 0.9679144385026738, intent accuracy: 1.0\n",
      "slot accuracy: 0.9827586206896551, intent accuracy: 1.0\n",
      "slot accuracy: 0.9382716049382716, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9782608695652174, intent accuracy: 0.9375\n",
      "slot accuracy: 0.956989247311828, intent accuracy: 1.0\n",
      "slot accuracy: 0.9827586206896551, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9319371727748691, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9701492537313433, intent accuracy: 1.0\n",
      "slot accuracy: 0.9710982658959537, intent accuracy: 1.0\n",
      "slot accuracy: 0.974025974025974, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9470588235294117, intent accuracy: 1.0\n",
      "slot accuracy: 0.9875776397515528, intent accuracy: 1.0\n",
      "slot accuracy: 0.9770114942528736, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9619047619047619, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9947089947089947, intent accuracy: 1.0\n",
      "slot accuracy: 0.958974358974359, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9886363636363636, intent accuracy: 1.0\n",
      "slot accuracy: 0.9832402234636871, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9649122807017544, intent accuracy: 1.0\n",
      "slot accuracy: 0.9222797927461139, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9751243781094527, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9672131147540983, intent accuracy: 1.0\n",
      "slot accuracy: 0.95, intent accuracy: 0.9375\n",
      "slot accuracy: 0.968944099378882, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9682539682539683, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9870967741935484, intent accuracy: 1.0\n",
      "slot accuracy: 0.9560439560439561, intent accuracy: 0.875\n",
      "slot accuracy: 0.9751243781094527, intent accuracy: 0.8125\n",
      "slot accuracy: 0.9911111111111112, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9873417721518988, intent accuracy: 1.0\n",
      "slot accuracy: 0.995260663507109, intent accuracy: 1.0\n",
      "F1 score for epoch 13: 0.9699920332831725\n",
      "Average train loss at epoch 14, step 0: 0.020459\n",
      "Average train loss at epoch 14, step 30: 0.024368\n",
      "Average train loss at epoch 14, step 60: 0.026484\n",
      "Average train loss at epoch 14, step 90: 0.023304\n",
      "Average train loss at epoch 14, step 120: 0.027130\n",
      "Average train loss at epoch 14, step 150: 0.025785\n",
      "Average train loss at epoch 14, step 180: 0.031600\n",
      "Average train loss at epoch 14, step 210: 0.027595\n",
      "Average train loss at epoch 14, step 240: 0.029490\n",
      "Average train loss at epoch 14, step 270: 0.035053\n",
      "[Epoch 14] Average train loss: 0.028132252108913222\n",
      "Input Sentence        :  ['how', 'many', 'first', 'class', 'flights', 'does', 'united', 'have', 'today', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Truth            :  ['O', 'O', 'B-class_type', 'I-class_type', 'O', 'O', 'B-airline_name', 'O', 'B-depart_date.today_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Slot Prediction       :  ['O', 'O', 'B-class_type', 'I-class_type', 'O', 'O', 'B-airline_name', 'O', 'B-depart_date.today_relative', 'B-depart_date.today_relative', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Intent Truth          :  atis_quantity\n",
      "Intent Prediction     :  atis_quantity\n",
      "slot accuracy: 0.9771428571428571, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9764705882352941, intent accuracy: 1.0\n",
      "slot accuracy: 0.9946524064171123, intent accuracy: 1.0\n",
      "slot accuracy: 0.9625, intent accuracy: 0.875\n",
      "slot accuracy: 0.92, intent accuracy: 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slot accuracy: 0.9484536082474226, intent accuracy: 0.875\n",
      "slot accuracy: 0.95, intent accuracy: 1.0\n",
      "slot accuracy: 0.987012987012987, intent accuracy: 1.0\n",
      "slot accuracy: 0.973404255319149, intent accuracy: 1.0\n",
      "slot accuracy: 0.9696969696969697, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9950248756218906, intent accuracy: 1.0\n",
      "slot accuracy: 0.9945945945945946, intent accuracy: 1.0\n",
      "slot accuracy: 0.9936305732484076, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9712643678160919, intent accuracy: 1.0\n",
      "slot accuracy: 0.9803921568627451, intent accuracy: 1.0\n",
      "slot accuracy: 0.9246231155778895, intent accuracy: 0.875\n",
      "slot accuracy: 0.9880952380952381, intent accuracy: 1.0\n",
      "slot accuracy: 0.9702970297029703, intent accuracy: 1.0\n",
      "slot accuracy: 0.9955357142857143, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9516129032258065, intent accuracy: 0.9375\n",
      "slot accuracy: 0.974025974025974, intent accuracy: 1.0\n",
      "slot accuracy: 0.9640287769784173, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9941520467836257, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9626168224299065, intent accuracy: 1.0\n",
      "slot accuracy: 0.976878612716763, intent accuracy: 1.0\n",
      "slot accuracy: 0.9950248756218906, intent accuracy: 1.0\n",
      "slot accuracy: 0.9943820224719101, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9704433497536946, intent accuracy: 0.875\n",
      "slot accuracy: 0.9879518072289156, intent accuracy: 0.875\n",
      "slot accuracy: 0.9624413145539906, intent accuracy: 0.9375\n",
      "slot accuracy: 0.9611111111111111, intent accuracy: 1.0\n",
      "F1 score for epoch 14: 0.9733948208584605\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    mean_loss = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(getBatch(batch_size, index_train)):\n",
    "        # Perform a batch training\n",
    "        _, loss_v, decoder_prediction_v, intent_v = step(sess, \"train\", batch)\n",
    "        mean_loss += loss_v\n",
    "        train_loss += loss_v\n",
    "        if i % 30 == 0:\n",
    "            if i > 0:\n",
    "                mean_loss = mean_loss / 30.0\n",
    "            print('Average train loss at epoch %d, step %d: %f' % (epoch, i, mean_loss))\n",
    "            mean_loss = 0\n",
    "    train_loss /= (i + 1)\n",
    "    print(\"[Epoch {}] Average train loss: {}\".format(epoch, train_loss))\n",
    "\n",
    "    # One epoch per training, test once\n",
    "    pred_slots = []\n",
    "    for j, batch in enumerate(getBatch(batch_size, index_test)):\n",
    "        decoder_prediction_v, intent_v = step(sess, \"test\", batch)\n",
    "        decoder_prediction_v = np.transpose(decoder_prediction_v, [1, 0])\n",
    "        if j == 0:\n",
    "            index = random.choice(range(len(batch)))\n",
    "            print(\"Input Sentence        : \", index_seq2word(batch[index][0], index2word))\n",
    "            print(\"Slot Truth            : \", index_seq2slot(batch[index][2], index2slot))\n",
    "            print(\"Slot Prediction       : \", index_seq2slot(decoder_prediction_v[index], index2slot))\n",
    "            print(\"Intent Truth          : \", index2intent[batch[index][3]])\n",
    "            print(\"Intent Prediction     : \", index2intent[intent_v[index]])\n",
    "        \n",
    "        slot_pred_length = list(np.shape(decoder_prediction_v))[1]\n",
    "        pred_padded = np.lib.pad(decoder_prediction_v, ((0, 0), (0, input_steps-slot_pred_length)),\n",
    "                                 mode=\"constant\", constant_values=0)\n",
    "        pred_slots.append(pred_padded)\n",
    "        true_slot = np.array((list(zip(*batch))[2]))\n",
    "        true_length = np.array((list(zip(*batch))[1]))\n",
    "        true_slot = true_slot[:, :slot_pred_length]\n",
    "        slot_acc = accuracy_score(true_slot, decoder_prediction_v, true_length)\n",
    "        intent_acc = accuracy_score(list(zip(*batch))[3], intent_v)\n",
    "        print(\"slot accuracy: {}, intent accuracy: {}\".format(slot_acc, intent_acc))\n",
    "    \n",
    "    pred_slots_a = np.vstack(pred_slots)\n",
    "    true_slots_a = np.array(list(zip(*index_test))[2])[:pred_slots_a.shape[0]]\n",
    "    print(\"F1 score for epoch {}: {}\".format(epoch, f1_for_sequence_batch(true_slots_a, pred_slots_a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['may', 'i', 'know', 'how', 'much', 'is', 'the', 'cheapest', 'flight', 'from', 'los', 'angeles', 'to', 'new', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'], '')\n"
     ]
    }
   ],
   "source": [
    "# in here type your inquire fpr the airline\n",
    "#my_sentence = 'list types of aircraft that fly between boston and san francisco'\n",
    "my_sentence = 'may I know how much is the cheapest flight from Los Angeles to New York'\n",
    "\n",
    "# this code will adapt your sentence to the input data structure\n",
    "input_data = ['BOS ' + my_sentence.lower() + '\\t\\n']\n",
    "input_data = data_pipeline(input_data, length=50)\n",
    "print(input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA STRUCTURE:\n",
      "ORIGINAL_index | UNPADDED_seqLength | LABELED_index | INDENT\n",
      "\n",
      "[[173, 22, 794, 582, 31, 133, 400, 515, 471, 782, 613, 715, 391, 172, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 14, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0]\n"
     ]
    }
   ],
   "source": [
    "# this will transfor the text into indices\n",
    "index_sentence = to_index(input_data, word2index, slot2index, intent2index)\n",
    "\n",
    "# this will augment the input size so it can later fit in the model\n",
    "index_sentence = index_sentence + index_test.copy()\n",
    "\n",
    "print('TEST DATA STRUCTURE:')\n",
    "print('ORIGINAL_index | UNPADDED_seqLength | LABELED_index | INDENT\\n')\n",
    "print(index_sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Sentence is      :  may I know how much is the cheapest flight from Los Angeles to New York \n",
      "\n",
      "Input Sentence        :  ['may', 'i', 'know', 'how', 'much', 'is', 'the', 'cheapest', 'flight', 'from', 'los', 'angeles', 'to', 'new', '<EOS>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'] \n",
      "\n",
      "Slot Prediction       :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-cost_relative', 'O', 'O', 'B-fromloc.city_name', 'I-fromloc.city_name', 'O', 'B-toloc.city_name', 'I-toloc.city_name', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'] \n",
      "\n",
      "Intent Prediction     :  atis_airfare\n"
     ]
    }
   ],
   "source": [
    "#### Output prediction for the text you input manually\n",
    "for j, batch in enumerate(getBatch2(batch_size, index_sentence)):\n",
    "    decoder_prediction_v, intent_v = step(sess, \"test\", batch)\n",
    "    decoder_prediction_v = np.transpose(decoder_prediction_v, [1, 0])\n",
    "    if j == 0:\n",
    "        index = 0\n",
    "        print(\"Your Sentence is      : \", my_sentence, \"\\n\")\n",
    "        print(\"Input Sentence        : \", index_seq2word(batch[index][0], index2word), \"\\n\")\n",
    "        print(\"Slot Prediction       : \", index_seq2slot(decoder_prediction_v[index], index2slot), \"\\n\")\n",
    "        print(\"Intent Prediction     : \", index2intent[intent_v[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
